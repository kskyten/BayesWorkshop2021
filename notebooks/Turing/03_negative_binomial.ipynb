{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using DrWatson\n@quickactivate \"BayesWorkshop2021\"\ninclude(joinpath(srcdir(), \"setup.jl\"));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling count data with the Negative Binomial\n\nWhen we considered modelling the data using a Poisson, we saw that the model didn't appear to fit as well to the data as we would like. In particular the model underpredicted low and high numbers of complaints, and overpredicted the medium number of complaints. This is one indication of over-dispersion, where the variance is larger than the mean. A Poisson model doesn't fit over-dispersed count data very well because the same parameter $\\lambda$, controls both the expected counts and the variance of these counts. The natural alternative to this is the negative binomial model:\n\n$$\n\\begin{align*}\n\\text{complaints}_{b,t} & \\sim \\text{Neg-Binomial}(\\lambda_{b,t}, \\phi) \\\\\n\\lambda_{b,t} & = \\exp{(\\eta_{b,t})} \\\\\n\\eta_{b,t} &= \\alpha + \\beta \\, {\\rm traps}_{b,t} + \\beta_{\\rm super} \\, {\\rm super}_{b} + \\text{log_sq_foot}_{b}\n\\end{align*}\n$$\n\nIn Stan the negative binomial mass function we'll use is called  $\\texttt{neg_binomial_2_log}(\\text{ints} \\, y, \\text{reals} \\, \\eta, \\text{reals} \\, \\phi)$  in Stan. Like the `poisson_log` function, this negative binomial mass function that is parameterized in terms of its log-mean, $\\eta$, but it also has a precision $\\phi$ such that\n\n$$\n\\mathbb{E}[y] \\, = \\lambda = \\exp(\\eta)\n$$\n\n$$\n\\text{Var}[y] = \\lambda + \\lambda^2/\\phi = \\exp(\\eta) + \\exp(\\eta)^2 / \\phi.\n$$\n\n\nAs $\\phi$ gets larger the term $\\lambda^2 / \\phi$ approaches zero and so  the variance of the negative-binomial approaches $\\lambda$, i.e., the negative-binomial gets closer and closer to the Poisson.\n\n### Fake data fit: Multiple NB regression\n\nWe're going to generate one draw from the fake data model so we can use the data to fit our model and compare the known values of the parameters to the posterior density of the parameters.\n\nCreate a dataset to feed into the model.\n\nNow we run our NB regression over the fake data and extract the samples to examine posterior predictive checks and to check whether we've sufficiently recovered our known parameters, $\\text{alpha}$ $\\texttt{beta}$, ."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\n\n# Convenience constructor for the mean-dispersion parameterization of `NegativeBinomial`.\nfunction NegativeBinomial2(μ, ϕ)\n    p = 1 / (1 + μ / ϕ)\n    r = ϕ\n\n    return NegativeBinomial(r, p)\nend\n\n@model function multiple_NB_regression(; traps, live_in_super, log_sq_foot, complaints=missing)\n    alpha ~ Normal(log(4), 1)\n    beta ~ Normal(-0.25, 1)\n    beta_super ~ Normal(-0.5, 1)\n    inv_phi ~ truncated(Normal(), 0, Inf)\n\n    # Allocate if we're going to sample.\n    complaints = complaints === missing ? Vector{Int}(undef, length(traps)) : complaints\n\n    # TODO: implement the full observe statement using `NegativeBinomial2`\n    @. complaints ~ ...\n\n    return (; alpha, beta, beta_super, inv_phi, complaints)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the vector of true values from your simulated dataset and compare to the recovered parameters."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N = size(pest_data, 1)\nmean_traps = mean(pest_data.traps)\nfake_traps = rand(filldist(Poisson(mean_traps), N))\nfake_obs = (traps = fake_traps,\n    live_in_super = rand(filldist(Bernoulli(0.5), N)),\n    log_sq_foot = rand(filldist(Normal(1.5, 0.1), N)),\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "fake_data = multiple_NB_regression(; fake_obs...)()"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "fake_post = sample(multiple_NB_regression(; fake_obs..., complaints=fake_data.complaints), NUTS(), 1_000)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mcmc_recover_hist(\n    fake_post,\n    (\n        alpha = fake_data.alpha,\n        beta = fake_data.beta,\n        beta_super = fake_data.beta_super,\n        inv_phi = fake_data.inv_phi\n    )\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit to real data and check the fit"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Add the `log_sq_foot` as in 02.\ntransform!(pest_data, :total_sq_foot => ByRow(total_sq_foot -> log(total_sq_foot / 1e4)) => :log_sq_foot)\n\nobs = (\n    traps = pest_data.traps,\n    live_in_super = pest_data.live_in_super,\n    log_sq_foot = pest_data.log_sq_foot\n)\npost = sample(multiple_NB_regression(; obs..., complaints=pest_data.complaints), NUTS(), 1_000)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at our predictions vs. the data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "yrep = posterior_predictive(multiple_NB_regression(; obs...), post)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_dens_overlay(pest_data.complaints, yrep[1:200])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that our model now captures both the number of small counts better as well as the tails.\n\nLet's check if the negative binomial model does a better job capturing the number of zeros:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using RCall\nggplot = rimport(\"ggplot2\")\n\nppc_stat(pest_data.complaints, yrep, stat = R\"function(x) mean(x == 0)\", binwidth = 0.01)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "These look OK, but let's look at the standardized residual plot."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Convert into a matrix of size `(num_variables, num_samples)`\nyrep_matrix = mapreduce(hcat, yrep) do y\n    y.complaints\nend;\n\nqqnorm(dropdims(mean(yrep_matrix; dims=2); dims=2), qqline=:R)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks OK, but we still have some very large *standardized* residuals. This might be because we are currently ignoring that the data are clustered by buildings, and that the probability of roach issue may vary substantially across buildings."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_rootogram(pest_data.complaints, yrep)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rootogram now looks much more plausible. We can tell this because now the expected number of complaints matches much closer to the observed number of complaints. However, we still have some larger counts that appear to be outliers for the model.\n\nCheck predictions by number of traps:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_intervals(pest_data.complaints, yrep, x = pest_data.traps) + ggplot.labs(x = \"Number of traps\", y = \"Number of complaints\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We haven't used the fact that the data are clustered by building yet. A posterior predictive check might elucidate whether it would be a good idea to add the building information into the model."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_stat_grouped(\n  pest_data.complaints,\n  yrep,\n  group = pest_data.building_id,\n  stat = \"mean\",\n  binwidth = 0.2\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're getting plausible predictions for most building means but some are estimated better than others and some have larger uncertainties than we might expect. If we explicitly model the variation across buildings we may be able to get much better estimates."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.6.2"
    },
    "kernelspec": {
      "name": "julia-1.6",
      "display_name": "Julia 1.6.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
