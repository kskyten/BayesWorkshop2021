{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using DrWatson\n@quickactivate \"BayesWorkshop2021\"\ninclude(joinpath(srcdir(), \"setup.jl\"));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hierarchical modeling\n\n### Modeling varying intercepts for each building\n\nLet's add a hierarchical intercept parameter, $\\alpha_b$ at the building level to our model.\n\n$$\n\\text{complaints}_{b,t} \\sim \\text{Neg-Binomial}(\\lambda_{b,t}, \\phi) \\\\\n\\lambda_{b,t}  = \\exp{(\\eta_{b,t})} \\\\\n\\eta_{b,t} = \\mu_b + \\beta \\, {\\rm traps}_{b,t} + \\beta_{\\rm super}\\, {\\rm super}_b + \\text{log_sq_foot}_b \\\\\n\\mu_b \\sim \\text{Normal}(\\alpha, \\sigma_{\\mu})\n$$\n\nIn our Stan model, $\\mu_b$ is the $b$-th element of the vector $\\texttt{mu}$ which has one element per building.\n\nOne of our predictors varies only by building, so we can rewrite the above model more efficiently like so:\n\n$$\n\\eta_{b,t} = \\mu_b + \\beta \\, {\\rm traps}_{b,t} + \\text{log_sq_foot}_b\\\\\n\\mu_b \\sim \\text{Normal}(\\alpha +  \\beta_{\\text{super}} \\, \\text{super}_b , \\sigma_{\\mu})\n$$\n\nWe have more information at the building level as well, like the average age of the residents, the average age of the buildings, and the average per-apartment monthly rent so we can add that data into a matrix called `building_data`, which will have one row per building and four columns:\n\n  * `live_in_super`\n  * `age_of_building`\n  * `average_tentant_age`\n  * `monthly_average_rent`\n\nWe'll write the Stan model like:\n\n$$\n\\eta_{b,t} = \\alpha_b + \\beta \\, {\\rm traps} + \\text{log_sq_foot}\\\\\n\\mu \\sim \\text{Normal}(\\alpha + \\texttt{building_data} \\, \\zeta, \\,\\sigma_{\\mu})\n$$\n\n### Prepare building data for hierarchical\n\nWe'll need to do some more data prep before we can fit our models. Firstly to use the building variable in Stan we will need to transform it from a factor variable to an integer variable."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "include(joinpath(srcdir(), \"building_data.jl\"))\nbuilding_data"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the hierarchical model\n\nFit the model to data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\n\nHalfNormal(args...) = truncated(Normal(args...), 1e-6, Inf)\n\nfunction NegativeBinomial2(μ, ϕ)\n    p = 1 / (1 + μ / ϕ)\n    r = ϕ\n\n    return NegativeBinomial(r, p)\nend\n\n@model function hier_NB_regression(; traps, live_in_super, log_sq_foot, building_idx, building_data, complaints=missing)\n    J, K = size(building_data)\n\n    sigma_mu ~ HalfNormal() # standard deviation of building-specific intercepts\n    alpha ~ Normal(log(4), 1) # intercept of model for mu\n    zeta ~ filldist(Normal(), K)  # coefficients on building-level predictors in model for mu\n    beta ~ Normal(-0.25, 1) # coefficient on traps\n    inv_phi ~ HalfNormal() # 1/phi (easier to think about prior for 1/phi instead of phi)\n\n    # TODO: Implement\n    mu ~ ...\n\n\n    # Allocate if we're going to sample.\n    complaints = complaints === missing ? Vector{Int}(undef, length(traps)) : complaints\n    @. complaints ~ NegativeBinomial2(\n        clamp(exp(mu[building_idx] + beta * traps + log_sq_foot), 1e-3, 1e5),\n        clamp(inv(inv_phi), 1e-3, 100)\n    )\n    return (; sigma_mu, alpha, zeta, beta, mu, inv_phi, complaints)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Add the `log_sq_foot` as in 02.\ntransform!(pest_data, :total_sq_foot => ByRow(total_sq_foot -> log(total_sq_foot / 1e4)) => :log_sq_foot)\n\nobs = (\n    traps = pest_data.traps,\n    live_in_super = pest_data.live_in_super,\n    log_sq_foot = pest_data.log_sq_foot,\n    building_idx = pest_data.building_idx,\n    building_data = building_data\n);\npost = sample(hier_NB_regression(; obs..., complaints=pest_data.complaints), NUTS(), 1_000);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diagnostics\n\nWe get a bunch of warnings from Turing about divergent transitions, which is an indication that there may be regions of the posterior that have not been explored by the Markov chains.\n\nDivergences are discussed in more detail in the course slides as well as the **bayesplot** (MCMC diagnostics vignette)[http://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html] and [*A Conceptual Introduction to Hamiltonian Monte Carlo*](https://arxiv.org/abs/1701.02434).\n\nIn this example we will see that we have divergent transitions because we need to reparameterize our model - i.e., we will retain the overall structure of the model, but transform some of the parameters so that it is easier for Stan to sample from the parameter space. Before we go through exactly how to do this reparameterization, we will first go through what indicates that this is something that reparameterization will resolve. We will go through:\n\n1. Examining the fitted parameter values, including the effective sample size\n2. Traceplots and scatterplots that reveal particular patterns in locations of the divergences.\n\nFirst the chain:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "post"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the effective samples are somewhat low for many of the parameters relative to the total number of samples. This alone isn't indicative of the need to reparameterize, but it indicates that we should look further at the trace plots and pairs plots. First let's look at the traceplots to see if the divergent transitions form a pattern."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using StatsPlots\nplot(post[[:sigma_mu]])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# NOTE: If it fails because of argument error, just run until it doesn't.\n# The prior is somewhat numerically unstable.\nidata = to_arviz(\n    hier_NB_regression(; obs...), # prior model\n    hier_NB_regression(; obs..., complaints=pest_data.complaints), # conditioned model\n    post # posterior samples\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks as if the divergent parameters, the little black bars underneath the traceplots correspond to samples where the sampler gets stuck at one parameter value for $\\sigma_\\mu$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot_trace(idata, var_names=[\"sigma_mu\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can look at the joint distribution of `sigma_mu` with one of the means:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "let\n    df = transform(\n        DataFrame(post[[:sigma_mu, Symbol(\"mu[4]\")]]),\n        :sigma_mu => ByRow(log) => :log_sigma_mu,\n        # `StatsPlots.@df` isn't to happy about `Symbol(...)`, so we\n        # just rename it to `:mu4`.\n        Symbol(\"mu[4]\") => identity => :mu4\n    )\n    @df df cornerplot([:log_sigma_mu :mu4], compact=true)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we have here is a cloud-like shape, with most of the divergences clustering towards the bottom. We'll see a bit later that we actually want this to look more like a funnel than a cloud, but the divergences are indicating that the sampler can't explore the narrowing neck of the funnel.\n\nOne way to see why we should expect some version of a funnel is to look at some simulations from the prior, which we can do without MCMC and thus with no risk of sampling problems:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prior_samples = sample(hier_NB_regression(; obs..., complaints=pest_data.complaints), Prior(), 1_000);\nlet chain = prior_samples\n    df = transform(\n        DataFrame(chain[[:sigma_mu, Symbol(\"mu[4]\")]]),\n        :sigma_mu => ByRow(log) => :log_sigma_mu,\n        # `StatsPlots.@df` isn't to happy about `Symbol(...)`, so we\n        # just rename it to `:mu4`.\n        Symbol(\"mu[4]\") => identity => :mu4\n    )\n    @df df cornerplot([:log_sigma_mu :mu4], compact=true)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, if the data is at all informative we shouldn't expect the posterior to look exactly like the prior. But unless the data is incredibly informative about the parameters and the posterior concentrates away from the narrow neck of the funnel, the sampler is going to have to confront the funnel geometry. (See the [Visual MCMC Diagnostics](http://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html) vignette for more on this.)\n\nAnother way to look at the divergences is via a parallel coordinates plot:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot_parallel(idata, var_names=[\"sigma_mu\", \"mu\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we see evidence that our problems concentrate when $\\texttt{sigma_mu}$ is small.\n\n### Reparameterize and recheck diagnostics\n\nInstead, we should use the non-centered parameterization for $\\mu_b$. We define a vector of auxiliary variables in the parameters block, $\\texttt{mu_raw}$ that is given a $\\text{Normal}(0, 1)$ prior in the model block. We then make $\\texttt{mu}$ a transformed parameter: We can reparameterize the random intercept $\\mu_b$, which is distributed:\n\n$$\n\\mu_b \\sim \\text{Normal}(\\alpha + \\texttt{building_data} \\, \\zeta, \\sigma_{\\mu})\n$$\n\nThis gives $\\texttt{mu}$ a $\\text{Normal}(\\alpha + \\texttt{building_data}\\, \\zeta, \\sigma_\\mu)$ distribution, but it decouples the dependence of the density of each element of $\\texttt{mu}$ from $\\texttt{sigma_mu}$ ($\\sigma_\\mu$). We will examine the effective sample size of the fitted model to see whether we've fixed the problem with our reparameterization.\n\nFit the model to the data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function hier_NB_regression_ncp(; traps, live_in_super, log_sq_foot, building_idx, building_data, complaints=missing)\n    J, K = size(building_data)\n\n    sigma_mu ~ HalfNormal()\n    alpha ~ Normal(log(4), 1)\n    zeta ~ filldist(Normal(), K)  # could also use informative priors on the different elements\n    beta ~ Normal(-0.25, 1)\n    inv_phi ~ HalfNormal()\n    mu_raw ~ filldist(Normal(), J)\n\n    mu  = alpha .+ building_data * zeta .+ sigma_mu .* mu_raw\n\n    # Allocate if we're going to sample.\n    complaints = complaints === missing ? Vector{Int}(undef, length(traps)) : complaints\n    @. complaints ~ NegativeBinomial2(\n        clamp(exp(mu[building_idx] + beta * traps + log_sq_foot), 1e-3, 1e5),\n        clamp(inv(inv_phi), 1e-3, 100)\n    )\n    return (; sigma_mu, alpha, zeta, beta, mu, inv_phi, complaints)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examining the fit of the new model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "post_ncp = sample(hier_NB_regression_ncp(; obs..., complaints=pest_data.complaints), NUTS(), 1_000);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This has improved the effective sample sizes of $\\texttt{mu}$. We now run our usual posterior predictive checks."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "idata_ncp = to_arviz(\n    hier_NB_regression_ncp(; obs...), # prior model\n    hier_NB_regression_ncp(; obs..., complaints=pest_data.complaints), # conditioned model\n    post_ncp # posterior samples\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Now that `mu` isn't on the LHS of a `~` anymore, it won't be present in\n# the resulting chain. Instead we need to extract it using `generated_quantities`:\ngenerated = generated_quantities(\n    hier_NB_regression_ncp(; obs..., complaints=pest_data.complaints),\n    MCMCChains.get_sections(post_ncp, :parameters)\n);\n\nlet\n    # Extract `mu[4]` from `generated`.\n    mu4 = mapreduce(vcat, generated) do g\n        g.mu[4]\n    end\n\n    # Construct the `DataFrame`.\n    df = select(\n        DataFrame(post_ncp[[:sigma_mu]]),\n        :sigma_mu => ByRow(log) => :log_sigma_mu,\n    )\n    # Add `mu[4]` to the `DataFrame.`\n    df = DataFrame(:log_sigma_mu => df.log_sigma_mu, :mu4 => mu4)\n    # Plot!\n    @df df cornerplot([:log_sigma_mu :mu4], compact=true)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot_trace(idata_ncp, var_names=[\"sigma_mu\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot_parallel(idata_ncp, var_names=[\"sigma_mu\", \"mu_raw\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the numerical errors are now much reduced (depending on your random seed, they might be completely gone!)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "yrep = posterior_predictive(hier_NB_regression_ncp(; obs...), post_ncp)\nppc_dens_overlay(pest_data.complaints, yrep[1:200])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks quite nice. If we've captured the building-level means well, then the posterior distribution of means by building should match well with the observed means of the quantity of building complaints by month."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_stat_grouped(pest_data.complaints, yrep, group=pest_data.building_idx, stat=\"mean\", binwidth=0.5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We weren't doing terribly with the building-specific means before, but now they are all well-captured by our model. The model is also able to do a decent job estimating within-building variability:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_stat_grouped(pest_data.complaints, yrep, group=pest_data.building_idx, stat=\"sd\", binwidth=0.5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions by number of traps:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using RCall\nggplot = rimport(\"ggplot2\")\n\nppc_intervals(pest_data.complaints, yrep, x=pest_data.traps) + ggplot.labs(x = \"Number of traps\", y = \"Number of complaints\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardized residuals:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Convert into a matrix of size `(num_variables, num_samples)`\nyrep_matrix = mapreduce(hcat, yrep) do y\n    y.complaints\nend;\n\nqqnorm(dropdims(mean(yrep_matrix; dims=2); dims=2), qqline=:R)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rootogram:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_rootogram(pest_data.complaints, yrep)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Varying intercepts *and* varying slopes\n\nWe've gotten some new data that extends the number of time points for which we have observations for each building. This will let us explore how to expand the model a bit more with varying *slopes* in addition to the varying intercepts and also, later, also model temporal variation."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "let path = datadir(\"pest_data_longer_stan_dat.rds\")\n    R\"\"\"\n    stan_dat_hier <- readRDS($path)\n    \"\"\"\nend\npest_data_longer = rcopy(R\"stan_dat_hier\")\npest_data_longer = (; pairs(pest_data_longer)...)\npest_data_longer = merge(\n    pest_data_longer, \n    (complaints = Int.(pest_data_longer.complaints), traps = Int.(pest_data_longer.traps))\n)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhaps if the levels of complaints differ by building, the coefficient for the effect of traps on building does too. We can add this to our model and observe the fit.\n\n$$\n\\text{complaints}_{b,t} \\sim \\text{Neg-Binomial}(\\lambda_{b,t}, \\phi)  \\\\\n\\lambda_{b,t} = \\exp{(\\eta_{b,t})}\\\\\n\\eta_{b,t} = \\mu_b + \\kappa_b \\, \\texttt{traps}_{b,t} + \\text{log_sq_foot}_b \\\\\n\\mu_b \\sim \\text{Normal}(\\alpha + \\texttt{building_data} \\, \\zeta, \\sigma_{\\mu}) \\\\\n\\kappa_b \\sim \\text{Normal}(\\beta + \\texttt{building_data} \\, \\gamma, \\sigma_{\\kappa})\n$$\n\nFit the model to data and extract the posterior draws needed for our posterior predictive checks."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function hier_NB_regression_ncp_slopes(; traps, log_sq_foot, building_idx, building_data, complaints)\n    J, K = size(building_data)\n\n    # TODO: Implement\n    kappa_raw ~ ...\n    sigma_kappa ~ ...\n    gamma ~ ...\n\n    sigma_mu ~ HalfNormal()\n    alpha ~ Normal(log(4), 1)\n    zeta ~ filldist(Normal(), K)  # could also use informative priors on the different elements\n    beta ~ Normal(-0.25, 1)\n    inv_phi ~ HalfNormal()\n    mu_raw ~ filldist(Normal(), J)\n\n    mu  = alpha .+ building_data * zeta .+ sigma_mu * mu_raw\n    # TODO Implement\n    kappa = ...\n\n    # Allocate if we're going to sample.\n    complaints = complaints === missing ? Vector{Int}(undef, length(traps)) : complaints\n    @. complaints ~ NegativeBinomial2(\n        exp(mu[building_idx] + kappa[building_idx] * traps + log_sq_foot),\n        inv(inv_phi)\n    )\n    return (; sigma_mu, sigma_kappa, gamma, alpha, zeta, beta, mu, kappa, inv_phi, complaints)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "obs = (\n    traps = pest_data_longer.traps,\n    log_sq_foot = pest_data_longer.log_sq_foot,\n    building_idx = pest_data_longer.building_idx,\n    building_data = building_data\n);\n\npost_ncp_slopes = sample(hier_NB_regression_ncp_slopes(; obs..., complaints=pest_data_longer.complaints), NUTS(), 1_000)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see if the model infers building-to-building differences in, we can plot a histogram of our marginal posterior distribution for `sigma_kappa`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(post_ncp_slopes[[:sigma_kappa]])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(MCMCChains.group(post_ncp_slopes, :kappa_raw))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the model can't specifically rule out zero from the posterior, it does have mass at small non-zero numbers, so we should leave in the hierarchy over $\\texttt{kappa}$. Plotting the marginal data density again, we can see the model still looks well calibrated."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "yrep = posterior_predictive(hier_NB_regression_ncp_slopes(; obs...), post_ncp_slopes)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_dens_overlay(pest_data_longer.complaints, yrep[1:200])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_stat_grouped(pest_data_longer.complaints, yrep, group=pest_data_longer.building_idx, stat=\"mean\", binwidth=0.5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_stat_grouped(pest_data_longer.complaints, yrep, group=pest_data_longer.building_idx, stat=\"sd\", binwidth=0.5)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_intervals(pest_data_longer.complaints, yrep, x=pest_data_longer.traps) + ggplot.labs(x = \"Number of traps\", y = \"Number of complaints\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ppc_rootogram(pest_data_longer.complaints, yrep)"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.6.2"
    },
    "kernelspec": {
      "name": "julia-1.6",
      "display_name": "Julia 1.6.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
